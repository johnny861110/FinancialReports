# éƒ¨ç½²æŒ‡å—

## ğŸš€ éƒ¨ç½²é¸é …

### 1. æœ¬åœ°éƒ¨ç½²

#### ç³»çµ±éœ€æ±‚
- Python 3.8+
- 2GB+ RAM
- 10GB+ ç£ç¢Ÿç©ºé–“
- ç¶²è·¯é€£ç·š

#### å®‰è£æ­¥é©Ÿ

```bash
# 1. å…‹éš†å°ˆæ¡ˆ
git clone <repository-url>
cd FinancialReports

# 2. å®‰è£UV (å¦‚æœªå®‰è£)
curl -LsSf https://astral.sh/uv/install.sh | sh

# 3. å®‰è£ä¾è³´
uv sync

# 4. å»ºç«‹å¿…è¦ç›®éŒ„
mkdir -p data/financial_reports data/processed logs

# 5. è¨­å®šé…ç½®
cp config/crawler_config.json.example config/crawler_config.json
# ç·¨è¼¯é…ç½®æª”æ¡ˆ...

# 6. æ¸¬è©¦å®‰è£
uv run python main.py --help
```

### 2. Docker éƒ¨ç½²

#### å»ºç«‹æ˜ åƒ

```bash
# å»ºç«‹Dockeræ˜ åƒ
docker build -t financial-reports:latest .

# æˆ–ä½¿ç”¨docker-compose
docker-compose build
```

#### åŸ·è¡Œå®¹å™¨

```bash
# åŸºæœ¬åŸ·è¡Œ
docker run -d \
  --name financial-reports \
  -v $(pwd)/data:/app/data \
  -v $(pwd)/config:/app/config \
  financial-reports:latest

# ä½¿ç”¨docker-compose
docker-compose up -d
```

#### Docker Compose é…ç½®

å»ºç«‹ `docker-compose.yml`:

```yaml
version: '3.8'

services:
  financial-reports:
    build: .
    container_name: financial-reports
    volumes:
      - ./data:/app/data
      - ./config:/app/config
      - ./logs:/app/logs
    environment:
      - PYTHONPATH=/app
    restart: unless-stopped
    command: ["tail", "-f", "/dev/null"]  # ä¿æŒå®¹å™¨é‹è¡Œ

  # å¯é¸ï¼šè³‡æ–™åº«æœå‹™
  postgres:
    image: postgres:13
    container_name: financial-db
    environment:
      POSTGRES_DB: financial_reports
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"

volumes:
  postgres_data:
```

### 3. é›²ç«¯éƒ¨ç½²

#### AWS éƒ¨ç½²

ä½¿ç”¨ AWS EC2 + ECS:

```bash
# 1. å»ºç«‹ECRå€‰åº«
aws ecr create-repository --repository-name financial-reports

# 2. å»ºç«‹ä¸¦æ¨é€æ˜ åƒ
docker build -t financial-reports .
docker tag financial-reports:latest <account-id>.dkr.ecr.<region>.amazonaws.com/financial-reports:latest
docker push <account-id>.dkr.ecr.<region>.amazonaws.com/financial-reports:latest

# 3. å»ºç«‹ECSä»»å‹™å®šç¾©
aws ecs register-task-definition --cli-input-json file://task-definition.json
```

#### Google Cloud éƒ¨ç½²

ä½¿ç”¨ Cloud Run:

```bash
# 1. å»ºç«‹æ˜ åƒä¸¦æ¨é€åˆ°GCR
gcloud builds submit --tag gcr.io/PROJECT-ID/financial-reports

# 2. éƒ¨ç½²åˆ°Cloud Run
gcloud run deploy financial-reports \
  --image gcr.io/PROJECT-ID/financial-reports \
  --platform managed \
  --region asia-east1 \
  --allow-unauthenticated
```

## âš™ï¸ ç’°å¢ƒé…ç½®

### 1. ç’°å¢ƒè®Šæ•¸

å»ºç«‹ `.env` æª”æ¡ˆ:

```bash
# æ‡‰ç”¨è¨­å®š
APP_ENV=production
LOG_LEVEL=INFO
DATA_DIR=/app/data
CONFIG_DIR=/app/config

# è³‡æ–™åº«è¨­å®š (å¯é¸)
DATABASE_URL=postgresql://user:password@localhost:5432/financial_reports

# OCRè¨­å®š
OCR_ENGINE=easyocr
USE_GPU=false

# çˆ¬èŸ²è¨­å®š
DOWNLOAD_DELAY=2
MAX_RETRY=3
TIMEOUT=30
```

### 2. é…ç½®æª”æ¡ˆ

#### `config/crawler_config.json`
```json
{
  "base_url": "https://doc.twse.com.tw",
  "output_dir": "data/financial_reports",
  "download_delay": 2,
  "max_retry": 3,
  "timeout": 30,
  "user_agent": "Mozilla/5.0 (compatible; FinancialReportsCrawler/2.0)",
  "headers": {
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
    "Accept-Language": "zh-TW,zh;q=0.9,en;q=0.8"
  }
}
```

#### `config/processor_config.json`
```json
{
  "ocr_engine": "easyocr",
  "languages": ["ch_tra", "en"],
  "use_gpu": false,
  "confidence_threshold": 0.7,
  "text_threshold": 0.3,
  "batch_size": 10
}
```

## ğŸ“Š ç›£æ§èˆ‡æ—¥èªŒ

### 1. æ—¥èªŒé…ç½®

å»ºç«‹ `config/logging.json`:

```json
{
  "version": 1,
  "formatters": {
    "default": {
      "format": "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    }
  },
  "handlers": {
    "console": {
      "class": "logging.StreamHandler",
      "formatter": "default"
    },
    "file": {
      "class": "logging.FileHandler",
      "filename": "logs/app.log",
      "formatter": "default"
    }
  },
  "root": {
    "level": "INFO",
    "handlers": ["console", "file"]
  }
}
```

### 2. å¥åº·æª¢æŸ¥

å»ºç«‹å¥åº·æª¢æŸ¥ç«¯é» (`health_check.py`):

```python
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import json
import sys
from pathlib import Path
from datetime import datetime

def health_check():
    """ç³»çµ±å¥åº·æª¢æŸ¥"""
    status = {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "version": "2.0.0",
        "checks": {}
    }
    
    # æª¢æŸ¥ç›®éŒ„æ˜¯å¦å­˜åœ¨
    required_dirs = ["data", "config", "logs"]
    for dir_name in required_dirs:
        if Path(dir_name).exists():
            status["checks"][f"{dir_name}_dir"] = "ok"
        else:
            status["checks"][f"{dir_name}_dir"] = "missing"
            status["status"] = "unhealthy"
    
    # æª¢æŸ¥é…ç½®æª”æ¡ˆ
    config_file = Path("config/crawler_config.json")
    if config_file.exists():
        status["checks"]["config"] = "ok"
    else:
        status["checks"]["config"] = "missing"
        status["status"] = "unhealthy"
    
    return status

if __name__ == "__main__":
    result = health_check()
    print(json.dumps(result, indent=2))
    sys.exit(0 if result["status"] == "healthy" else 1)
```

### 3. ç³»çµ±ç›£æ§

ä½¿ç”¨ Prometheus + Grafana é€²è¡Œç›£æ§:

å»ºç«‹ `monitoring/prometheus.yml`:

```yaml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'financial-reports'
    static_configs:
      - targets: ['localhost:8000']
    metrics_path: /metrics
    scrape_interval: 30s
```

## ğŸ”’ å®‰å…¨æ€§é…ç½®

### 1. æª”æ¡ˆæ¬Šé™

```bash
# è¨­å®šæ­£ç¢ºçš„æª”æ¡ˆæ¬Šé™
chmod 600 config/*.json
chmod 700 logs/
chmod 755 scripts/*.py
```

### 2. é˜²ç«ç‰†è¨­å®š

```bash
# Ubuntu/Debian
ufw allow 22/tcp
ufw allow 8000/tcp
ufw enable

# CentOS/RHEL
firewall-cmd --permanent --add-port=22/tcp
firewall-cmd --permanent --add-port=8000/tcp
firewall-cmd --reload
```

### 3. SSL/TLS é…ç½®

å¦‚éœ€è¦HTTPSï¼Œä½¿ç”¨nginxåå‘ä»£ç†:

```nginx
server {
    listen 443 ssl http2;
    server_name your-domain.com;
    
    ssl_certificate /path/to/certificate.crt;
    ssl_certificate_key /path/to/private.key;
    
    location / {
        proxy_pass http://localhost:8000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
}
```

## ğŸ”§ ç¶­è­·ä»»å‹™

### 1. å®šæœŸå‚™ä»½

å»ºç«‹å‚™ä»½è…³æœ¬ (`scripts/backup.sh`):

```bash
#!/bin/bash

BACKUP_DIR="/backup/financial-reports"
DATE=$(date +%Y%m%d_%H%M%S)

# å»ºç«‹å‚™ä»½ç›®éŒ„
mkdir -p $BACKUP_DIR

# å‚™ä»½è³‡æ–™
tar -czf $BACKUP_DIR/data_$DATE.tar.gz data/
tar -czf $BACKUP_DIR/config_$DATE.tar.gz config/

# ä¿ç•™æœ€è¿‘30å¤©çš„å‚™ä»½
find $BACKUP_DIR -name "*.tar.gz" -mtime +30 -delete

echo "å‚™ä»½å®Œæˆ: $DATE"
```

### 2. æ—¥èªŒè¼ªè½‰

è¨­å®šlogrotate (`/etc/logrotate.d/financial-reports`):

```
/app/logs/*.log {
    daily
    missingok
    rotate 30
    compress
    delaycompress
    notifempty
    copytruncate
}
```

### 3. ç³»çµ±æ›´æ–°

å»ºç«‹æ›´æ–°è…³æœ¬ (`scripts/update.sh`):

```bash
#!/bin/bash

echo "é–‹å§‹æ›´æ–°ç³»çµ±..."

# åœæ­¢æœå‹™
docker-compose down

# æ‹‰å–æœ€æ–°ä»£ç¢¼
git pull origin main

# é‡å»ºæ˜ åƒ
docker-compose build

# é‡å•Ÿæœå‹™
docker-compose up -d

echo "æ›´æ–°å®Œæˆ"
```

## ğŸš¨ æ•…éšœæ’é™¤

### 1. å¸¸è¦‹å•é¡Œ

#### è¨˜æ†¶é«”ä¸è¶³
```bash
# æª¢æŸ¥è¨˜æ†¶é«”ä½¿ç”¨é‡
free -h
docker stats

# å¢åŠ swapç©ºé–“
sudo fallocate -l 2G /swapfile
sudo chmod 600 /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile
```

#### ç£ç¢Ÿç©ºé–“ä¸è¶³
```bash
# æ¸…ç†Docker
docker system prune -a

# æ¸…ç†èˆŠæ—¥èªŒ
find logs/ -name "*.log" -mtime +7 -delete

# æ¸…ç†è™•ç†éçš„æª”æ¡ˆ
find data/processed/ -mtime +30 -delete
```

### 2. é™¤éŒ¯æ¨¡å¼

å•Ÿç”¨é™¤éŒ¯æ¨¡å¼:

```bash
# è¨­å®šç’°å¢ƒè®Šæ•¸
export LOG_LEVEL=DEBUG
export APP_ENV=development

# åŸ·è¡Œæ‡‰ç”¨
uv run python main.py --debug
```

### 3. æ•ˆèƒ½èª¿å„ª

èª¿æ•´è™•ç†åƒæ•¸:

```json
{
  "batch_size": 5,
  "max_workers": 2,
  "memory_limit": "1GB",
  "timeout": 60
}
```

---

**éœ€è¦å”åŠ©ï¼Ÿè«‹æŸ¥çœ‹ [é–‹ç™¼æŒ‡å—](DEVELOPMENT.md) æˆ–è¯ç¹«ç³»çµ±ç®¡ç†å“¡ã€‚**
