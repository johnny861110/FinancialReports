#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
è²¡å‹™æ•¸æ“šå›å¡«å·¥å…· - æ•´åˆç‰ˆ
"""

import sys
import argparse
from pathlib import Path
from datetime import datetime
import os

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ°è·¯å¾‘
current_dir = Path(__file__).parent
project_root = current_dir.parent
sys.path.insert(0, str(project_root))

# ä½¿ç”¨ç›¸å°å°å…¥
from src.processors.smart_processor import SmartFinancialProcessor
from src.utils.helpers import setup_logging


class FinancialDataBackfiller:
    """è²¡å‹™æ•¸æ“šå›å¡«å·¥å…·"""
    
    def __init__(self, config=None):
        self.logger = setup_logging("FinancialDataBackfiller")
        self.processor = SmartFinancialProcessor(config)
    
    def backfill_single_file(self, enhanced_path: Path, original_path: Path):
        """å›å¡«å–®ä¸€æª”æ¡ˆ"""
        self.logger.info(f"ğŸ”„ é–‹å§‹å›å¡«: {enhanced_path.name} -> {original_path.name}")
        
        result = self.processor.backfill_to_original_json(enhanced_path, original_path)
        
        if result.success:
            self.logger.info(f"âœ… å›å¡«æˆåŠŸ!")
            
            # é¡¯ç¤ºæ›´æ–°æ‘˜è¦
            if 'updated_fields' in result.data:
                self._show_update_summary(result.data['updated_fields'])
            
            return True
        else:
            self.logger.error(f"âŒ å›å¡«å¤±æ•—: {result.message}")
            return False
    
    def backfill_directory(self, data_dir: Path):
        """å›å¡«ç›®éŒ„ä¸­çš„æ‰€æœ‰æª”æ¡ˆ"""
        self.logger.info(f"ğŸ”„ é–‹å§‹æ‰¹æ¬¡å›å¡«: {data_dir}")
        
        result = self.processor.batch_backfill(data_dir)
        
        if result.success:
            data = result.data
            self.logger.info(f"âœ… æ‰¹æ¬¡å›å¡«å®Œæˆ!")
            self.logger.info(f"ğŸ“Š æˆåŠŸ: {data['success_count']}/{data['total_files']} æª”æ¡ˆ")
            
            # é¡¯ç¤ºè©³ç´°çµæœ
            print("\nğŸ“‹ è™•ç†çµæœ:")
            print("=" * 80)
            
            for file_result in data['results']:
                status = "âœ…" if file_result['success'] else "âŒ"
                print(f"{status} {file_result['enhanced_file']} -> {file_result['original_file']}")
                if not file_result['success']:
                    print(f"   éŒ¯èª¤: {file_result['message']}")
            
            return data
        else:
            self.logger.error(f"âŒ æ‰¹æ¬¡å›å¡«å¤±æ•—: {result.message}")
            return None
    
    def _show_update_summary(self, updated_fields):
        """é¡¯ç¤ºæ›´æ–°æ‘˜è¦"""
        financials_updates = updated_fields.get('financials', [])
        income_updates = updated_fields.get('income_statement', [])
        
        total_updates = len(financials_updates) + len(income_updates)
        
        if total_updates == 0:
            print("   â„¹ï¸  æ²’æœ‰æ¬„ä½éœ€è¦æ›´æ–°")
            return
        
        print(f"   ğŸ“Š æ›´æ–°äº† {total_updates} å€‹è²¡å‹™æ¬„ä½:")
        
        if financials_updates:
            print("   ğŸ’° è³‡ç”¢è² å‚µè¡¨:")
            for update in financials_updates:
                old_val = update['old_value'] if update['old_value'] is not None else "ç„¡"
                new_val = update['new_value']
                print(f"      - {update['field']}: {old_val} â†’ {new_val}")
        
        if income_updates:
            print("   ğŸ“ˆ æç›Šè¡¨:")
            for update in income_updates:
                old_val = update['old_value'] if update['old_value'] is not None else "ç„¡"
                new_val = update['new_value']
                print(f"      - {update['field']}: {old_val} â†’ {new_val}")
    
    def find_backfill_pairs(self, data_dir: Path):
        """å°‹æ‰¾å¯ä»¥å›å¡«çš„æª”æ¡ˆå°"""
        processed_dir = data_dir / "processed"
        
        if not processed_dir.exists():
            self.logger.warning("æ‰¾ä¸åˆ°processedç›®éŒ„")
            return []
        
        enhanced_files = list(processed_dir.glob("*_enhanced.json"))
        pairs = []
        
        for enhanced_file in enhanced_files:
            original_name = enhanced_file.name.replace('_enhanced.json', '.json')
            original_file = data_dir / original_name
            
            if original_file.exists():
                pairs.append({
                    'enhanced': enhanced_file,
                    'original': original_file,
                    'status': 'ready'
                })
            else:
                pairs.append({
                    'enhanced': enhanced_file,
                    'original': original_name,
                    'status': 'missing_original'
                })
        
        return pairs
    
    def show_status(self, data_dir: Path):
        """é¡¯ç¤ºå›å¡«ç‹€æ…‹"""
        pairs = self.find_backfill_pairs(data_dir)
        
        print("ğŸ” å›å¡«ç‹€æ…‹æª¢æŸ¥")
        print("=" * 60)
        print(f"ğŸ“ è³‡æ–™ç›®éŒ„: {data_dir}")
        
        ready_pairs = [p for p in pairs if p['status'] == 'ready']
        missing_pairs = [p for p in pairs if p['status'] == 'missing_original']
        
        print(f"âœ… å¯å›å¡«æª”æ¡ˆå°: {len(ready_pairs)}")
        print(f"âŒ ç¼ºå°‘åŸå§‹æª”æ¡ˆ: {len(missing_pairs)}")
        
        if ready_pairs:
            print("\nğŸ“‹ å¯å›å¡«çš„æª”æ¡ˆ:")
            for pair in ready_pairs[:10]:  # åªé¡¯ç¤ºå‰10å€‹
                print(f"  - {pair['enhanced'].name} -> {pair['original'].name}")
            if len(ready_pairs) > 10:
                print(f"  ... é‚„æœ‰ {len(ready_pairs) - 10} å€‹æª”æ¡ˆå°")
        
        if missing_pairs:
            print("\nâš ï¸  ç¼ºå°‘åŸå§‹æª”æ¡ˆ:")
            for pair in missing_pairs:
                print(f"  - {pair['enhanced'].name} (æ‰¾ä¸åˆ° {pair['original']})")


def main():
    """ä¸»å‡½æ•¸"""
    parser = argparse.ArgumentParser(description='è²¡å‹™æ•¸æ“šå›å¡«å·¥å…·')
    parser.add_argument('--enhanced', help='å¢å¼·JSONæª”æ¡ˆè·¯å¾‘')
    parser.add_argument('--original', help='åŸå§‹JSONæª”æ¡ˆè·¯å¾‘')
    parser.add_argument('--directory', help='æ‰¹æ¬¡è™•ç†ç›®éŒ„')
    parser.add_argument('--status', help='æª¢æŸ¥å›å¡«ç‹€æ…‹çš„ç›®éŒ„')
    parser.add_argument('--config', help='é…ç½®æª”æ¡ˆè·¯å¾‘')
    
    args = parser.parse_args()
    
    # è¼‰å…¥é…ç½®
    config = None
    if args.config:
        config_path = Path(args.config)
        if config_path.exists():
            import json
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
    
    backfiller = FinancialDataBackfiller(config)
    
    # æª¢æŸ¥ç‹€æ…‹
    if args.status:
        status_dir = Path(args.status)
        backfiller.show_status(status_dir)
        return
    
    # æ‰¹æ¬¡å›å¡«
    if args.directory:
        directory_path = Path(args.directory)
        if not directory_path.exists():
            print(f"âŒ ç›®éŒ„ä¸å­˜åœ¨: {directory_path}")
            return
        
        backfiller.backfill_directory(directory_path)
        return
    
    # å–®ä¸€æª”æ¡ˆå›å¡«
    if args.enhanced and args.original:
        enhanced_path = Path(args.enhanced)
        original_path = Path(args.original)
        
        if not enhanced_path.exists():
            print(f"âŒ å¢å¼·JSONæª”æ¡ˆä¸å­˜åœ¨: {enhanced_path}")
            return
        
        if not original_path.exists():
            print(f"âŒ åŸå§‹JSONæª”æ¡ˆä¸å­˜åœ¨: {original_path}")
            return
        
        success = backfiller.backfill_single_file(enhanced_path, original_path)
        if success:
            print("ğŸ‰ å›å¡«å®Œæˆ!")
        return
    
    # å¦‚æœæ²’æœ‰æä¾›åƒæ•¸ï¼Œé¡¯ç¤ºå¹«åŠ©
    parser.print_help()


if __name__ == "__main__":
    main()
