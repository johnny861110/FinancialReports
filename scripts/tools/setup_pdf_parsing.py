#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å®‰è£PDFè§£æä¾è³´ä¸¦æ¸¬è©¦å®Œæ•´è²¡å ±è§£æåŠŸèƒ½
"""

import subprocess
import sys
from pathlib import Path

def install_pypdf2():
    """å®‰è£PyPDF2æ¨¡çµ„"""
    try:
        print("ğŸ”„ å®‰è£PyPDF2æ¨¡çµ„...")
        subprocess.check_call([sys.executable, "-m", "pip", "install", "PyPDF2"])
        print("âœ… PyPDF2å®‰è£æˆåŠŸ")
        return True
    except subprocess.CalledProcessError as e:
        print(f"âŒ PyPDF2å®‰è£å¤±æ•—: {e}")
        return False

def test_pdf_parsing():
    """æ¸¬è©¦PDFè§£æåŠŸèƒ½"""
    try:
        import PyPDF2
        print("âœ… PyPDF2å°å…¥æˆåŠŸ")
        
        # å°‹æ‰¾å·²ä¸‹è¼‰çš„PDFæª”æ¡ˆé€²è¡Œæ¸¬è©¦
        pdf_files = list(Path("data/diagnostic_results").rglob("*.pdf"))
        
        if pdf_files:
            test_pdf = pdf_files[0]
            print(f"ğŸ” æ¸¬è©¦è§£æPDF: {test_pdf}")
            
            with open(test_pdf, 'rb') as file:
                reader = PyPDF2.PdfReader(file)
                text = ""
                for page in reader.pages:
                    text += page.extract_text()
                
                print(f"âœ… PDFè§£ææˆåŠŸï¼Œæå–äº† {len(text)} å­—ç¬¦")
                print(f"ğŸ“„ å…§å®¹é è¦½ï¼ˆå‰200å­—ç¬¦ï¼‰:")
                print(text[:200])
                
                return True
        else:
            print("âš ï¸ æ‰¾ä¸åˆ°PDFæª”æ¡ˆé€²è¡Œæ¸¬è©¦")
            return False
            
    except Exception as e:
        print(f"âŒ PDFè§£ææ¸¬è©¦å¤±æ•—: {e}")
        return False

def create_enhanced_parser():
    """å‰µå»ºå¢å¼·ç‰ˆè²¡å ±è§£æå™¨"""
    
    enhanced_content = '''#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å¢å¼·ç‰ˆè¨ºæ–·æ‰¹æ¬¡çˆ¬èŸ² - å®Œæ•´PDFè§£æåŠŸèƒ½
"""

import sys
import json
import time
import re
import PyPDF2
from pathlib import Path
from datetime import datetime

# æ·»åŠ crawlersç›®éŒ„åˆ°Pythonè·¯å¾‘
sys.path.insert(0, str(Path(__file__).parent / 'crawlers'))

from improved_twse_crawler import ImprovedTWSEFinancialCrawler

# === å®Œæ•´çš„è²¡å ±è§£æåŠŸèƒ½ ===

def extract_text_from_pdf(pdf_path):
    """å¾PDFæª”æ¡ˆæå–æ–‡å­—å…§å®¹ï¼ˆå®Œæ•´ç‰ˆï¼‰"""
    try:
        with open(pdf_path, 'rb') as file:
            reader = PyPDF2.PdfReader(file)
            text = ""
            for page in reader.pages:
                text += page.extract_text()
            return text
    except Exception as e:
        print(f"âŒ PDFè®€å–å¤±æ•—: {e}")
        return ""

def reparse_existing_pdfs():
    """é‡æ–°è§£æå·²å­˜åœ¨çš„PDFæª”æ¡ˆ"""
    
    print("ğŸ”„ é‡æ–°è§£æå·²ä¸‹è¼‰çš„PDFæª”æ¡ˆ...")
    
    pdf_files = list(Path("data/diagnostic_results").rglob("*.pdf"))
    
    if not pdf_files:
        print("âš ï¸ æ‰¾ä¸åˆ°å·²ä¸‹è¼‰çš„PDFæª”æ¡ˆ")
        return
    
    print(f"ğŸ“‹ æ‰¾åˆ° {len(pdf_files)} å€‹PDFæª”æ¡ˆ")
    
    parsed_count = 0
    
    for pdf_path in pdf_files:
        try:
            # å¾æª”æ¡ˆè·¯å¾‘è§£æå…¬å¸è³‡è¨Š
            parts = pdf_path.parts
            stock_code = parts[-3]  # ä¾‹å¦‚: 2330
            period_info = parts[-2]  # ä¾‹å¦‚: 2024Q1
            
            year = int(period_info[:4])
            quarter = int(period_info[-1])
            
            # ç°¡å–®çš„å…¬å¸åç¨±æ˜ å°„
            company_names = {
                '2330': 'å°ç©é›»',
                '2454': 'è¯ç™¼ç§‘',
                '2317': 'é´»æµ·'
            }
            company_name = company_names.get(stock_code, f'å…¬å¸{stock_code}')
            
            print(f"ğŸ” é‡æ–°è§£æ: {stock_code} ({company_name}) {year}Q{quarter}")
            
            # ä½¿ç”¨å®Œæ•´è§£æåŠŸèƒ½
            from diagnostic_batch_crawler import parse_financial_report
            
            parsed_data = parse_financial_report(pdf_path, stock_code, company_name, year, quarter)
            
            if parsed_data:
                # å„²å­˜æ–°çš„JSONæª”æ¡ˆ
                json_path = pdf_path.with_suffix('.json')
                with open(json_path, 'w', encoding='utf-8') as f:
                    json.dump(parsed_data, f, ensure_ascii=False, indent=2)
                
                print(f"   âœ… é‡æ–°è§£ææˆåŠŸ: {json_path.name}")
                parsed_count += 1
            else:
                print(f"   âŒ é‡æ–°è§£æå¤±æ•—")
                
        except Exception as e:
            print(f"   âŒ è™•ç†å¤±æ•—: {e}")
    
    print(f"\\nğŸ‰ é‡æ–°è§£æå®Œæˆ! æˆåŠŸè§£æ {parsed_count} å€‹æª”æ¡ˆ")

if __name__ == '__main__':
    reparse_existing_pdfs()
'''
    
    with open('enhanced_parser.py', 'w', encoding='utf-8') as f:
        f.write(enhanced_content)
    
    print("âœ… å¢å¼·ç‰ˆè§£æå™¨å·²å‰µå»º: enhanced_parser.py")

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸš€ é–‹å§‹è¨­ç½®å®Œæ•´PDFè§£æåŠŸèƒ½...")
    
    # å®‰è£PyPDF2
    if install_pypdf2():
        # æ¸¬è©¦PDFè§£æ
        if test_pdf_parsing():
            # å‰µå»ºå¢å¼·ç‰ˆè§£æå™¨
            create_enhanced_parser()
            
            print("\\nâœ… å®Œæ•´PDFè§£æåŠŸèƒ½è¨­ç½®å®Œæˆ!")
            print("\\nğŸ“‹ å¾ŒçºŒæ­¥é©Ÿ:")
            print("1. é‹è¡Œ enhanced_parser.py é‡æ–°è§£æå·²ä¸‹è¼‰çš„PDF")
            print("2. æˆ–ä¿®æ”¹ diagnostic_batch_crawler.py å•Ÿç”¨å®Œæ•´è§£æ")
            print("3. æª¢æŸ¥ç”Ÿæˆçš„JSONæª”æ¡ˆæ˜¯å¦åŒ…å«å®Œæ•´è²¡å‹™æ•¸æ“š")
        else:
            print("\\nâŒ PDFè§£ææ¸¬è©¦å¤±æ•—ï¼Œè«‹æª¢æŸ¥éŒ¯èª¤è¨Šæ¯")
    else:
        print("\\nâŒ PyPDF2å®‰è£å¤±æ•—ï¼Œç„¡æ³•å•Ÿç”¨å®Œæ•´PDFè§£æ")

if __name__ == '__main__':
    main()
