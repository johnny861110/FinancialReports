#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ™ºæ…§è™•ç†è…³æœ¬
"""

import sys
import argparse
from pathlib import Path
from datetime import datetime

# ä½¿ç”¨æ¨™æº– Python åŒ…å°å…¥
from src.processors.smart_processor import SmartFinancialProcessor
from src.utils.helpers import setup_logging, create_progress_reporter


class SmartProcessorApp:
    """æ™ºæ…§è™•ç†æ‡‰ç”¨ç¨‹å¼"""
    
    def __init__(self, config=None):
        self.logger = setup_logging("SmartProcessorApp")
        self.processor = SmartFinancialProcessor(config)
    
    def process_single(self, pdf_path: Path, json_path: Path, output_path: Path = None):
        """è™•ç†å–®ä¸€æª”æ¡ˆ"""
        self.logger.info(f"æ™ºæ…§è™•ç†: {pdf_path.name}")
        
        result = self.processor.process(pdf_path, json_path, output_path)
        
        if result.success:
            self.logger.info(f"âœ… è™•ç†æˆåŠŸ: {result.message}")
            return result.data
        else:
            self.logger.error(f"âŒ è™•ç†å¤±æ•—: {result.message}")
            return None
    
    def process_batch(self, data_dir: Path):
        """æ‰¹æ¬¡è™•ç†ç›®éŒ„ä¸­çš„æ‰€æœ‰æª”æ¡ˆ"""
        if not data_dir.exists():
            self.logger.error(f"ç›®éŒ„ä¸å­˜åœ¨: {data_dir}")
            return
        
        # å°‹æ‰¾PDFå’Œå°æ‡‰çš„JSONæª”æ¡ˆ
        pdf_files = list(data_dir.glob("*.pdf"))
        file_pairs = []
        
        for pdf_file in pdf_files:
            json_file = pdf_file.with_suffix('.json')
            if json_file.exists():
                file_pairs.append((pdf_file, json_file))
            else:
                self.logger.warning(f"æ‰¾ä¸åˆ°å°æ‡‰çš„JSONæª”æ¡ˆ: {json_file}")
        
        if not file_pairs:
            self.logger.warning("æœªæ‰¾åˆ°å¯è™•ç†çš„æª”æ¡ˆå°")
            return
        
        self.logger.info(f"æ‰¾åˆ° {len(file_pairs)} å€‹æª”æ¡ˆå°é€²è¡Œè™•ç†")
        
        # æ‰¹æ¬¡è™•ç†
        progress = create_progress_reporter(len(file_pairs), "æ™ºæ…§è™•ç†")
        success_count = 0
        
        for pdf_path, json_path in file_pairs:
            try:
                result = self.process_single(pdf_path, json_path)
                if result:
                    success_count += 1
            except Exception as e:
                self.logger.error(f"è™•ç† {pdf_path.name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            
            progress.update()
        
        progress.finish()
        self.logger.info(f"æ‰¹æ¬¡è™•ç†å®Œæˆ: {success_count}/{len(file_pairs)} æˆåŠŸ")
    
    def check_processed_status(self, data_dir: Path):
        """æª¢æŸ¥è™•ç†ç‹€æ…‹"""
        if not data_dir.exists():
            self.logger.error(f"ç›®éŒ„ä¸å­˜åœ¨: {data_dir}")
            return
        
        pdf_files = list(data_dir.glob("*.pdf"))
        processed_dir = data_dir / "processed"
        
        print("ğŸ” è™•ç†ç‹€æ…‹æª¢æŸ¥")
        print("=" * 50)
        print(f"ğŸ“ è³‡æ–™ç›®éŒ„: {data_dir}")
        print(f"ğŸ“„ PDFæª”æ¡ˆæ•¸é‡: {len(pdf_files)}")
        
        if processed_dir.exists():
            processed_files = list(processed_dir.glob("*_enhanced.json"))
            print(f"âœ… å·²è™•ç†æª”æ¡ˆ: {len(processed_files)}")
            print(f"ğŸ”„ å¾…è™•ç†æª”æ¡ˆ: {len(pdf_files) - len(processed_files)}")
            
            # é¡¯ç¤ºæœªè™•ç†çš„æª”æ¡ˆ
            processed_names = {f.name.replace('_enhanced.json', '.pdf') for f in processed_files}
            unprocessed = [f for f in pdf_files if f.name not in processed_names]
            
            if unprocessed:
                print("\nğŸ“‹ å¾…è™•ç†æª”æ¡ˆ:")
                for file in unprocessed[:10]:  # åªé¡¯ç¤ºå‰10å€‹
                    print(f"  - {file.name}")
                if len(unprocessed) > 10:
                    print(f"  ... é‚„æœ‰ {len(unprocessed) - 10} å€‹æª”æ¡ˆ")
        else:
            print("âŒ å°šæœªå»ºç«‹è™•ç†ç›®éŒ„")
    
    def backfill_single(self, enhanced_path: Path, original_path: Path):
        """å›å¡«å–®ä¸€æª”æ¡ˆ"""
        self.logger.info(f"é–‹å§‹å›å¡«: {enhanced_path.name} -> {original_path.name}")
        
        result = self.processor.backfill_to_original_json(enhanced_path, original_path)
        
        if result.success:
            self.logger.info(f"âœ… å›å¡«æˆåŠŸ: {result.message}")
            if 'updated_fields' in result.data:
                updated_fields = result.data['updated_fields']
                total_updates = len(updated_fields['financials']) + len(updated_fields['income_statement'])
                self.logger.info(f"ğŸ“Š æ›´æ–°äº† {total_updates} å€‹è²¡å‹™æ¬„ä½")
            return result.data
        else:
            self.logger.error(f"âŒ å›å¡«å¤±æ•—: {result.message}")
            return None
    
    def backfill_batch(self, data_dir: Path):
        """æ‰¹æ¬¡å›å¡«ç›®éŒ„ä¸­çš„æ‰€æœ‰æª”æ¡ˆ"""
        self.logger.info(f"é–‹å§‹æ‰¹æ¬¡å›å¡«: {data_dir}")
        
        result = self.processor.batch_backfill(data_dir)
        
        if result.success:
            data = result.data
            self.logger.info(f"âœ… æ‰¹æ¬¡å›å¡«å®Œæˆ: {data['success_count']}/{data['total_files']} æˆåŠŸ")
            
            # é¡¯ç¤ºè©³ç´°çµæœ
            for file_result in data['results']:
                if file_result['success']:
                    self.logger.info(f"  âœ… {file_result['enhanced_file']} -> {file_result['original_file']}")
                else:
                    self.logger.error(f"  âŒ {file_result['enhanced_file']}: {file_result['message']}")
            
            return data
        else:
            self.logger.error(f"âŒ æ‰¹æ¬¡å›å¡«å¤±æ•—: {result.message}")
            return None


def main():
    """ä¸»å‡½æ•¸"""
    parser = argparse.ArgumentParser(description='æ™ºæ…§è²¡å ±è™•ç†å™¨')
    parser.add_argument('pdf_path', nargs='?', help='PDFæª”æ¡ˆè·¯å¾‘')
    parser.add_argument('json_path', nargs='?', help='å°æ‡‰çš„JSONæª”æ¡ˆè·¯å¾‘')
    parser.add_argument('-o', '--output', help='è¼¸å‡ºæª”æ¡ˆè·¯å¾‘')
    parser.add_argument('--batch', help='æ‰¹æ¬¡è™•ç†ç›®éŒ„')
    parser.add_argument('--status', help='æª¢æŸ¥è™•ç†ç‹€æ…‹çš„ç›®éŒ„')
    parser.add_argument('--config', help='é…ç½®æª”æ¡ˆè·¯å¾‘')
    parser.add_argument('--backfill', help='å›å¡«å¢å¼·æ•¸æ“šåˆ°åŸå§‹JSON')
    parser.add_argument('--backfill-batch', help='æ‰¹æ¬¡å›å¡«ç›®éŒ„ä¸­çš„æ‰€æœ‰æª”æ¡ˆ')
    parser.add_argument('--enhanced-file', help='å¢å¼·JSONæª”æ¡ˆè·¯å¾‘ï¼ˆç”¨æ–¼å–®ä¸€å›å¡«ï¼‰')
    parser.add_argument('--original-file', help='åŸå§‹JSONæª”æ¡ˆè·¯å¾‘ï¼ˆç”¨æ–¼å–®ä¸€å›å¡«ï¼‰')
    
    args = parser.parse_args()
    
    # è¼‰å…¥é…ç½®
    config = None
    if args.config:
        config_path = Path(args.config)
        if config_path.exists():
            import json
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
    
    app = SmartProcessorApp(config)
    
    # æª¢æŸ¥ç‹€æ…‹
    if args.status:
        status_dir = Path(args.status)
        app.check_processed_status(status_dir)
        return
    
    # æ‰¹æ¬¡è™•ç†
    if args.batch:
        batch_dir = Path(args.batch)
        app.process_batch(batch_dir)
        return
    
    # å–®ä¸€æª”æ¡ˆè™•ç†
    if args.pdf_path and args.json_path:
        pdf_path = Path(args.pdf_path)
        json_path = Path(args.json_path)
        output_path = Path(args.output) if args.output else None
        
        if not pdf_path.exists():
            print(f"âŒ PDFæª”æ¡ˆä¸å­˜åœ¨: {pdf_path}")
            return
        
        if not json_path.exists():
            print(f"âŒ JSONæª”æ¡ˆä¸å­˜åœ¨: {json_path}")
            return
        
        result = app.process_single(pdf_path, json_path, output_path)
        if result:
            print(f"âœ… è™•ç†å®Œæˆ: {result.get('output_path')}")
        return
    
    # æ‰¹æ¬¡å›å¡«
    if args.backfill_batch:
        batch_dir = Path(args.backfill_batch)
        app.backfill_batch(batch_dir)
        return
    
    # å–®ä¸€æª”æ¡ˆå›å¡«
    if args.backfill and args.enhanced_file and args.original_file:
        enhanced_path = Path(args.enhanced_file)
        original_path = Path(args.original_file)
        
        if not enhanced_path.exists():
            print(f"âŒ å¢å¼·JSONæª”æ¡ˆä¸å­˜åœ¨: {enhanced_path}")
            return
        
        if not original_path.exists():
            print(f"âŒ åŸå§‹JSONæª”æ¡ˆä¸å­˜åœ¨: {original_path}")
            return
        
        result = app.backfill_single(enhanced_path, original_path)
        if result:
            print(f"âœ… å›å¡«å®Œæˆ")
        return

    # å¦‚æœæ²’æœ‰æä¾›åƒæ•¸ï¼Œé¡¯ç¤ºå¹«åŠ©
    parser.print_help()


if __name__ == "__main__":
    main()
