#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ä¸»è¦çˆ¬èŸ²è…³æœ¬
çµ±ä¸€çš„è²¡å ±çˆ¬èŸ²å…¥å£é»
"""

import sys
import json
import argparse
from pathlib import Path
from typing import Dict, Any, List, Union
from datetime import datetime

# ä½¿ç”¨æ¨™æº– Python åŒ…å°å…¥
from src.core import ConfigManager
from src.core.crawler import FinancialCrawler
from src.utils.helpers import (
    setup_logging, load_json, save_json, validate_stock_code, 
    validate_season, normalize_season, create_progress_reporter, format_file_size
)


class FinancialCrawlerApp:
    """è²¡å ±çˆ¬èŸ²æ‡‰ç”¨ç¨‹å¼"""
    
    def __init__(self):
        self.logger = setup_logging("FinancialCrawlerApp")
        self.config = ConfigManager.load_config()
        self.crawler = FinancialCrawler(self.config)
    
    def run_single_query(self, query_data: Dict[str, Any]) -> Dict[str, Any]:
        """åŸ·è¡Œå–®ç­†æŸ¥è©¢"""
        # é©—è­‰è¼¸å…¥
        if not self._validate_query(query_data):
            return {"success": False, "error": "Invalid query data"}
        
        # æ¨™æº–åŒ–è³‡æ–™
        query_data = self._normalize_query(query_data)
        
        # åŸ·è¡Œçˆ¬å–
        result = self.crawler.process(query_data)
        return result.to_dict()
    
    def run_batch_query(self, queries_data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åŸ·è¡Œæ‰¹æ¬¡æŸ¥è©¢"""
        # é©—è­‰æ‰€æœ‰æŸ¥è©¢
        valid_queries = []
        for i, query in enumerate(queries_data):
            if self._validate_query(query):
                valid_queries.append(self._normalize_query(query))
            else:
                self.logger.warning(f"è·³éç„¡æ•ˆæŸ¥è©¢ #{i+1}: {query}")
        
        if not valid_queries:
            return {"success": False, "error": "No valid queries found"}
        
        # åŸ·è¡Œæ‰¹æ¬¡çˆ¬å–
        result = self.crawler.process(valid_queries)
        return result.to_dict()
    
    def show_statistics(self) -> None:
        """é¡¯ç¤ºçµ±è¨ˆè³‡è¨Š"""
        data_dir = Path(self.config['output_dir'])
        processed_dir = Path(self.config['processed_dir'])
        
        # è¨ˆç®—æª”æ¡ˆæ•¸é‡
        pdf_files = list(data_dir.glob("*.pdf")) if data_dir.exists() else []
        json_files = list(data_dir.glob("*.json")) if data_dir.exists() else []
        processed_files = list(processed_dir.glob("*.json")) if processed_dir.exists() else []
        
        print("ğŸ“Š è²¡å ±çˆ¬èŸ²çµ±è¨ˆè³‡è¨Š")
        print("=" * 50)
        print(f"ğŸ“„ PDFæª”æ¡ˆ: {len(pdf_files)}")
        print(f"ğŸ“‹ JSONæª”æ¡ˆ: {len(json_files)}")
        print(f"ğŸ”„ å·²è™•ç†æª”æ¡ˆ: {len(processed_files)}")
        print(f"ğŸ“ è¼¸å‡ºç›®éŒ„: {data_dir}")
        print(f"ğŸ“ è™•ç†ç›®éŒ„: {processed_dir}")
        
        # é¡¯ç¤ºæœ€è¿‘çš„æª”æ¡ˆ
        if pdf_files:
            latest_pdf = max(pdf_files, key=lambda x: x.stat().st_mtime)
            print(f"ğŸ“… æœ€æ–°PDF: {latest_pdf.name}")
    
    def search_reports(self, search_term: str) -> None:
        """æœå°‹è²¡å ±"""
        data_dir = Path(self.config['output_dir'])
        
        if not data_dir.exists():
            print("âŒ è³‡æ–™ç›®éŒ„ä¸å­˜åœ¨")
            return
        
        # æœå°‹PDFæª”æ¡ˆ
        found_files = []
        for pdf_file in data_dir.glob("*.pdf"):
            if search_term.lower() in pdf_file.name.lower():
                found_files.append(pdf_file)
        
        print(f"ğŸ” æœå°‹çµæœ (é—œéµå­—: {search_term})")
        print("=" * 50)
        
        if found_files:
            for file in found_files:
                file_size = file.stat().st_size
                print(f"ğŸ“„ {file.name} ({format_file_size(file_size)})")
        else:
            print("âŒ æœªæ‰¾åˆ°ç›¸é—œæª”æ¡ˆ")
    
    def _validate_query(self, query: Dict[str, Any]) -> bool:
        """é©—è­‰æŸ¥è©¢è³‡æ–™"""
        required_fields = ['stock_code', 'company_name', 'year', 'season']
        
        for field in required_fields:
            if field not in query:
                self.logger.error(f"ç¼ºå°‘å¿…è¦æ¬„ä½: {field}")
                return False
        
        if not validate_stock_code(query['stock_code']):
            self.logger.error(f"ç„¡æ•ˆçš„è‚¡ç¥¨ä»£ç¢¼: {query['stock_code']}")
            return False
        
        if not validate_season(str(query['season'])):
            self.logger.error(f"ç„¡æ•ˆçš„å­£åº¦: {query['season']}")
            return False
        
        try:
            year = int(query['year'])
            if year < 2020 or year > 2030:
                self.logger.error(f"ç„¡æ•ˆçš„å¹´ä»½: {year}")
                return False
        except ValueError:
            self.logger.error(f"ç„¡æ•ˆçš„å¹´ä»½æ ¼å¼: {query['year']}")
            return False
        
        return True
    
    def _normalize_query(self, query: Dict[str, Any]) -> Dict[str, Any]:
        """æ¨™æº–åŒ–æŸ¥è©¢è³‡æ–™"""
        normalized = query.copy()
        normalized['season'] = normalize_season(str(query['season']))
        normalized['year'] = int(query['year'])
        return normalized


def main():
    """ä¸»å‡½æ•¸"""
    parser = argparse.ArgumentParser(description='å°ç£è²¡å ±çˆ¬èŸ²')
    parser.add_argument('input', nargs='?', help='JSONè¼¸å…¥æª”æ¡ˆæˆ–JSONå­—ä¸²')
    parser.add_argument('--batch', help='æ‰¹æ¬¡æŸ¥è©¢æª”æ¡ˆ')
    parser.add_argument('--stock-code', help='è‚¡ç¥¨ä»£ç¢¼')
    parser.add_argument('--company', help='å…¬å¸åç¨±')
    parser.add_argument('--year', type=int, help='å¹´ä»½')
    parser.add_argument('--season', help='å­£åº¦ (Q1, Q2, Q3, Q4)')
    parser.add_argument('--stats', action='store_true', help='é¡¯ç¤ºçµ±è¨ˆè³‡è¨Š')
    parser.add_argument('--search', help='æœå°‹è²¡å ±')
    parser.add_argument('--output-dir', help='è¼¸å‡ºç›®éŒ„')
    
    args = parser.parse_args()
    
    app = FinancialCrawlerApp()
    
    # è¦†è“‹é…ç½®
    if args.output_dir:
        app.config['output_dir'] = args.output_dir
    
    # é¡¯ç¤ºçµ±è¨ˆ
    if args.stats:
        app.show_statistics()
        return
    
    # æœå°‹åŠŸèƒ½
    if args.search:
        app.search_reports(args.search)
        return
    
    # å‘½ä»¤åˆ—å–®ç­†æŸ¥è©¢
    if all([args.stock_code, args.company, args.year, args.season]):
        query = {
            'stock_code': args.stock_code,
            'company_name': args.company,
            'year': args.year,
            'season': args.season
        }
        result = app.run_single_query(query)
        print(json.dumps(result, ensure_ascii=False, indent=2))
        return
    
    # æ‰¹æ¬¡æŸ¥è©¢
    if args.batch:
        batch_file = Path(args.batch)
        if not batch_file.exists():
            print(f"âŒ æ‰¹æ¬¡æª”æ¡ˆä¸å­˜åœ¨: {batch_file}")
            return
        
        queries = load_json(batch_file)
        result = app.run_batch_query(queries)
        
        # å„²å­˜çµæœ
        output_dir = Path("output")
        output_dir.mkdir(exist_ok=True)
        result_file = output_dir / f"batch_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        save_json(result, result_file)
        print(f"âœ… æ‰¹æ¬¡çµæœå·²å„²å­˜: {result_file}")
        return
    
    # JSONè¼¸å…¥
    if args.input:
        try:
            # å˜—è©¦è§£æç‚ºJSONå­—ä¸²
            if args.input.startswith('{') or args.input.startswith('['):
                data = json.loads(args.input)
            else:
                # ç•¶ä½œæª”æ¡ˆè·¯å¾‘
                data = load_json(Path(args.input))
            
            if isinstance(data, list):
                result = app.run_batch_query(data)
            else:
                result = app.run_single_query(data)
            
            print(json.dumps(result, ensure_ascii=False, indent=2))
            
        except Exception as e:
            print(f"âŒ è¼¸å…¥è™•ç†å¤±æ•—: {e}")
            return
    
    # å¦‚æœæ²’æœ‰ä»»ä½•æ“ä½œï¼Œé¡¯ç¤ºå¹«åŠ©
    if not any([args.input, args.batch, args.stats, args.search, 
               all([args.stock_code, args.company, args.year, args.season])]):
        parser.print_help()


if __name__ == "__main__":
    main()
