#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ¸¬è©¦å°ˆç”¨ï¼šæŠ“å–å°ç©é›»2330 2025Q1è²¡å ±
"""

import sys
import json
import time
from pathlib import Path
from datetime import datetime

# æ·»åŠ crawlersç›®éŒ„åˆ°Pythonè·¯å¾‘
sys.path.insert(0, str(Path(__file__).parent / 'crawlers'))

from improved_twse_crawler import ImprovedTWSEFinancialCrawler

def test_tsmc_2025q1():
    """æ¸¬è©¦æŠ“å–å°ç©é›»2025Q1è²¡å ±"""
    
    print("ğŸš€ æ¸¬è©¦æŠ“å–å°ç©é›»(2330) 2025Q1è²¡å ±")
    print("=" * 50)
    
    # è¨­å®šè¼¸å‡ºç›®éŒ„
    output_dir = Path(__file__).parent / 'data' / 'test_results'
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # åˆå§‹åŒ–çˆ¬èŸ²
    print("ğŸ“¥ åˆå§‹åŒ–çˆ¬èŸ²...")
    crawler = ImprovedTWSEFinancialCrawler(max_retries=3, retry_delay=2)
    
    # æ¸¬è©¦åƒæ•¸
    stock_code = "2330"
    company_name = "å°ç©é›»"
    year = 2025
    quarter = 1
    
    print(f"ğŸ“‹ ç›®æ¨™ï¼š{company_name}({stock_code}) {year}Q{quarter}")
    print("-" * 30)
    
    try:
        # åŸ·è¡ŒæŸ¥è©¢
        print("ğŸ” é–‹å§‹æŸ¥è©¢è²¡å ±...")
        result = crawler.query_financial_reports(
            stock_code=stock_code,
            year=year,
            quarter=quarter,
            report_type='ifrs_consolidated'
        )
        
        print(f"ğŸ“Š æŸ¥è©¢çµæœï¼š")
        if result and result.get('status') == 'success':
            pdf_files = result.get('pdf_files', [])
            print(f"   âœ… æ‰¾åˆ° {len(pdf_files)} å€‹è²¡å ±")
            
            # ä¸‹è¼‰æ¯å€‹PDF
            for i, pdf_info in enumerate(pdf_files, 1):
                filename = pdf_info.get('filename', f"unknown_{i}.pdf")
                print(f"   ğŸ“„ [{i}] æº–å‚™ä¸‹è¼‰: {filename}")
                
                # å»ºç«‹æª”æ¡ˆè·¯å¾‘
                file_path = output_dir / filename
                
                # æ§‹å»ºPDFä¸‹è¼‰é€£çµ
                pdf_link_info = {
                    'kind': pdf_info.get('kind', 'A'),
                    'co_id': pdf_info.get('co_id', stock_code),
                    'filename': filename,
                    'href': f"/server-java/t57sb01?TYPEK={pdf_info.get('kind', 'A')}&co_id={pdf_info.get('co_id', stock_code)}&filename={filename}"
                }
                
                # ä¸‹è¼‰PDF
                print(f"       ğŸ”— æº–å‚™ä¸‹è¼‰...")
                download_success = crawler.download_pdf_file(pdf_link_info, str(file_path))
                
                if download_success and file_path.exists():
                    actual_size = file_path.stat().st_size
                    print(f"       âœ… æª”æ¡ˆä¸‹è¼‰æˆåŠŸï¼Œå¤§å°: {actual_size:,} bytes")
                    
                    # ç”Ÿæˆå°æ‡‰çš„JSONæª”æ¡ˆ
                    json_path = file_path.with_suffix('.json')
                    json_data = {
                        "stock_code": stock_code,
                        "company_name": company_name,
                        "report_year": year,
                        "report_season": f"Q{quarter}",
                        "currency": "TWD",
                        "unit": "åƒå…ƒ",
                        "financials": {
                            "cash_and_equivalents": None,
                            "accounts_receivable": None,
                            "inventory": None,
                            "total_assets": None,
                            "total_liabilities": None,
                            "equity": None
                        },
                        "income_statement": {
                            "net_revenue": None,
                            "gross_profit": None,
                            "operating_income": None,
                            "net_income": None,
                            "eps": None
                        },
                        "metadata": {
                            "source": "doc.twse.com.tw",
                            "file_name": filename,
                            "file_path": str(file_path),
                            "file_size": actual_size,
                            "crawled_at": datetime.now().isoformat(),
                            "parser_version": "v3.1_test",
                            "note": "æ¸¬è©¦æ¨¡å¼ï¼šåŸºæœ¬çµæ§‹ï¼Œå¯æ“´å±•PDFå…§å®¹è§£æ"
                        }
                    }
                    
                    # å„²å­˜JSONæª”æ¡ˆ
                    with open(json_path, 'w', encoding='utf-8') as f:
                        json.dump(json_data, f, ensure_ascii=False, indent=2)
                    
                    print(f"       âœ… JSONå·²ç”Ÿæˆ: {json_path.name}")
                else:
                    print(f"       âŒ æª”æ¡ˆä¸‹è¼‰å¤±æ•—")
                    
            return True
        else:
            status = result.get('status', 'unknown') if result else 'no_result'
            message = result.get('message', 'æœªçŸ¥éŒ¯èª¤') if result else 'ç„¡å›æ‡‰'
            
            print(f"   âŒ æŸ¥è©¢å¤±æ•—: {status}")
            print(f"   ğŸ“ è©³ç´°è¨Šæ¯: {message}")
            print("   ğŸ’¡ å¯èƒ½åŸå› ï¼š")
            
            if status == 'no_data':
                print("      - 2025Q1è²¡å ±å°šæœªå…¬å¸ƒ")
            elif status == 'financial_holding':
                print("      - å°ç©é›»è¢«èª¤èªç‚ºé‡‘èæ§è‚¡å…¬å¸")
            elif status == 'server_error':
                print("      - TWSEä¼ºæœå™¨éŒ¯èª¤")
            else:
                print("      - ç¶²ç«™æŸ¥è©¢æ¢ä»¶éœ€è¦èª¿æ•´")
                print("      - ç¶²è·¯é€£ç·šå•é¡Œ")
            
            return False
            
    except Exception as e:
        print(f"âŒ æ¸¬è©¦éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
        print(f"   éŒ¯èª¤é¡å‹: {type(e).__name__}")
        import traceback
        print(f"   è©³ç´°éŒ¯èª¤: {traceback.format_exc()}")
        return False

def check_existing_data():
    """æª¢æŸ¥ç¾æœ‰çš„å°ç©é›»æ•¸æ“š"""
    print("\nğŸ” æª¢æŸ¥ç¾æœ‰å°ç©é›»æ•¸æ“š...")
    print("-" * 30)
    
    # æª¢æŸ¥ä¸»è¦æ•¸æ“šç›®éŒ„
    main_data_dir = Path(__file__).parent / 'data' / 'financial_reports_main' / 'by_company' / '2330_å°ç©é›»'
    
    if main_data_dir.exists():
        periods = [d.name for d in main_data_dir.iterdir() if d.is_dir()]
        periods.sort()
        
        print(f"ğŸ“ ç¾æœ‰æœŸé–“: {len(periods)} å€‹")
        for period in periods:
            period_dir = main_data_dir / period
            pdf_files = list(period_dir.glob("*.pdf"))
            json_files = list(period_dir.glob("*.json"))
            
            print(f"   ğŸ“… {period}: PDF={len(pdf_files)}, JSON={len(json_files)}")
    else:
        print("âŒ æœªæ‰¾åˆ°å°ç©é›»æ•¸æ“šç›®éŒ„")
    
    # æª¢æŸ¥æœå°‹ç´¢å¼•
    index_dir = Path(__file__).parent / 'data' / 'financial_reports_main' / 'search_indexes'
    if index_dir.exists():
        index_files = list(index_dir.glob("financial_index_*.json"))
        if index_files:
            latest_index = max(index_files, key=lambda x: x.stat().st_mtime)
            print(f"\nğŸ“Š æœ€æ–°æœå°‹ç´¢å¼•: {latest_index.name}")
            
            try:
                with open(latest_index, 'r', encoding='utf-8') as f:
                    index_data = json.load(f)
                
                if '2330' in index_data.get('companies', {}):
                    tsmc_data = index_data['companies']['2330']
                    periods = list(tsmc_data['periods'].keys())
                    print(f"   ğŸ¢ å°ç©é›»ç´¢å¼•æœŸé–“: {len(periods)} å€‹")
                    print(f"   ğŸ“… æœŸé–“åˆ—è¡¨: {', '.join(sorted(periods))}")
                else:
                    print("   âŒ ç´¢å¼•ä¸­æœªæ‰¾åˆ°å°ç©é›»æ•¸æ“š")
                    
            except Exception as e:
                print(f"   âŒ è®€å–ç´¢å¼•å¤±æ•—: {e}")

def main():
    """ä¸»ç¨‹å¼"""
    print("ğŸ§ª å°ç©é›»2330 2025Q1è²¡å ±æŠ“å–æ¸¬è©¦")
    print("=" * 60)
    
    # æª¢æŸ¥ç¾æœ‰æ•¸æ“š
    check_existing_data()
    
    # åŸ·è¡Œæ¸¬è©¦
    print(f"\nâ° é–‹å§‹æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    success = test_tsmc_2025q1()
    
    print(f"\nâ° çµæŸæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    if success:
        print("âœ… æ¸¬è©¦å®Œæˆï¼")
        
        # æª¢æŸ¥æ¸¬è©¦çµæœ
        test_dir = Path(__file__).parent / 'data' / 'test_results'
        if test_dir.exists():
            pdf_files = list(test_dir.glob("*.pdf"))
            json_files = list(test_dir.glob("*.json"))
            
            print(f"\nğŸ“Š æ¸¬è©¦çµæœçµ±è¨ˆ:")
            print(f"   ğŸ“„ PDFæª”æ¡ˆ: {len(pdf_files)} å€‹")
            print(f"   ğŸ”§ JSONæª”æ¡ˆ: {len(json_files)} å€‹")
            
            if pdf_files:
                print(f"\nğŸ“ æª”æ¡ˆä½ç½®: {test_dir}")
                for pdf_file in pdf_files:
                    size = pdf_file.stat().st_size
                    print(f"   ğŸ“„ {pdf_file.name} ({size:,} bytes)")
    else:
        print("âŒ æ¸¬è©¦å¤±æ•—")
        print("\nğŸ’¡ å»ºè­°ï¼š")
        print("   1. æª¢æŸ¥ç¶²è·¯é€£ç·š")
        print("   2. ç¢ºèª2025Q1è²¡å ±æ˜¯å¦å·²å…¬å¸ƒ")
        print("   3. å˜—è©¦å…¶ä»–æœŸé–“ï¼ˆå¦‚2024Q4ï¼‰")
        print("   4. æŸ¥çœ‹è©³ç´°éŒ¯èª¤è¨Šæ¯")

if __name__ == '__main__':
    main()
