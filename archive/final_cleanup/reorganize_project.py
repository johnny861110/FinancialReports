#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å°ˆæ¡ˆè³‡æ–™å¤¾æ•´ç†è…³æœ¬
æ¸…ç†é‡è¤‡æª”æ¡ˆã€æ•´ç†ç›®éŒ„çµæ§‹ã€çµ±ä¸€ç®¡ç†ä¸å¿…è¦çš„å…§å®¹
"""

import shutil
import json
from pathlib import Path
from datetime import datetime

def create_archive_folder():
    """å»ºç«‹æ­·å²æª”æ¡ˆå­˜æª”è³‡æ–™å¤¾"""
    archive_path = Path(__file__).parent / "archive"
    archive_path.mkdir(exist_ok=True)
    
    # å»ºç«‹å­è³‡æ–™å¤¾
    (archive_path / "old_docs").mkdir(exist_ok=True)
    (archive_path / "old_reports").mkdir(exist_ok=True)
    (archive_path / "duplicate_files").mkdir(exist_ok=True)
    (archive_path / "backup_data").mkdir(exist_ok=True)
    
    return archive_path

def identify_duplicate_docs():
    """è­˜åˆ¥é‡è¤‡çš„æ–‡æª”æª”æ¡ˆ"""
    base_path = Path(__file__).parent
    
    # æ ¹ç›®éŒ„ä¸­çš„é‡è¤‡æª”æ¡ˆ
    root_duplicates = [
        "FINAL_STATUS.md",
        "NEW_TARGETS_TEST_REPORT.md", 
        "PROJECT_COMPLETION_REPORT.md",
        "PROJECT_FINAL_STATUS.md",
        "PROJECT_STRUCTURE.md",
        "SIMPLIFIED_USAGE.md",
        "TEST_COMPLETION_REPORT.md",
        "USER_GUIDE.md"
    ]
    
    # docs è³‡æ–™å¤¾ä¸­é‡è¤‡çš„æª”æ¡ˆ
    docs_duplicates = [
        "docs/QUICK_START.md",  # æ ¹ç›®éŒ„å·²æœ‰
        "docs/README.md"        # å¯èƒ½é‡è¤‡
    ]
    
    return root_duplicates, docs_duplicates

def identify_redundant_data():
    """è­˜åˆ¥å†—é¤˜çš„è³‡æ–™æª”æ¡ˆ"""
    redundant_dirs = [
        "data/diagnostic_results",  # è¨ºæ–·çµæœï¼Œå¯æ­¸æª”
        "data/financial_reports_main",  # é‡è¤‡ç›®éŒ„
        "backup"  # èˆŠå‚™ä»½è³‡æ–™å¤¾
    ]
    
    return redundant_dirs

def move_to_archive(source_path, archive_path, category):
    """ç§»å‹•æª”æ¡ˆåˆ°å­˜æª”è³‡æ–™å¤¾"""
    if isinstance(source_path, str):
        source_path = Path(source_path)
    
    if not source_path.exists():
        print(f"   âš ï¸ æª”æ¡ˆä¸å­˜åœ¨: {source_path}")
        return False
    
    target_dir = archive_path / category
    target_path = target_dir / source_path.name
    
    try:
        if source_path.is_dir():
            if target_path.exists():
                shutil.rmtree(target_path)
            shutil.move(str(source_path), str(target_path))
            print(f"   ğŸ“ ç§»å‹•ç›®éŒ„: {source_path} -> archive/{category}/")
        else:
            shutil.move(str(source_path), str(target_path))
            print(f"   ğŸ“„ ç§»å‹•æª”æ¡ˆ: {source_path} -> archive/{category}/")
        return True
    except Exception as e:
        print(f"   âŒ ç§»å‹•å¤±æ•—: {source_path} - {e}")
        return False

def cleanup_empty_dirs(base_path):
    """æ¸…ç†ç©ºè³‡æ–™å¤¾"""
    empty_dirs = []
    
    for path in Path(base_path).rglob("*"):
        if path.is_dir() and not any(path.iterdir()):
            empty_dirs.append(path)
    
    for empty_dir in empty_dirs:
        try:
            empty_dir.rmdir()
            print(f"   ğŸ—‘ï¸ åˆªé™¤ç©ºè³‡æ–™å¤¾: {empty_dir}")
        except Exception as e:
            print(f"   âš ï¸ ç„¡æ³•åˆªé™¤è³‡æ–™å¤¾: {empty_dir} - {e}")

def create_cleanup_summary(archive_path, moved_files, moved_dirs):
    """å»ºç«‹æ¸…ç†æ‘˜è¦æª”æ¡ˆ"""
    summary = {
        "cleanup_date": datetime.now().isoformat(),
        "total_moved_files": len(moved_files),
        "total_moved_dirs": len(moved_dirs),
        "moved_files": moved_files,
        "moved_directories": moved_dirs,
        "archive_location": str(archive_path),
        "description": "å°ˆæ¡ˆæ•´ç† - ç§»é™¤é‡è¤‡å’Œä¸å¿…è¦çš„æª”æ¡ˆ"
    }
    
    summary_file = archive_path / "cleanup_summary.json"
    with open(summary_file, 'w', encoding='utf-8') as f:
        json.dump(summary, f, ensure_ascii=False, indent=2)
    
    print(f"   ğŸ“Š æ¸…ç†æ‘˜è¦å·²å„²å­˜: {summary_file}")

def reorganize_project():
    """é‡æ–°çµ„ç¹”å°ˆæ¡ˆçµæ§‹"""
    print("ğŸ—‚ï¸ é‡æ–°çµ„ç¹”å°ˆæ¡ˆçµæ§‹")
    print("-" * 40)
    
    base_path = Path(__file__).parent
    archive_path = create_archive_folder()
    
    moved_files = []
    moved_dirs = []
    
    print("1ï¸âƒ£ è™•ç†é‡è¤‡æ–‡æª”...")
    
    # è™•ç†æ ¹ç›®éŒ„é‡è¤‡æª”æ¡ˆ
    root_duplicates, docs_duplicates = identify_duplicate_docs()
    
    for file_name in root_duplicates:
        file_path = base_path / file_name
        if move_to_archive(file_path, archive_path, "old_docs"):
            moved_files.append(str(file_path))
    
    # è™•ç†docsä¸­çš„é‡è¤‡æª”æ¡ˆ  
    for file_path in docs_duplicates:
        full_path = base_path / file_path
        if move_to_archive(full_path, archive_path, "duplicate_files"):
            moved_files.append(str(full_path))
    
    print("\n2ï¸âƒ£ è™•ç†å†—é¤˜è³‡æ–™ç›®éŒ„...")
    
    redundant_dirs = identify_redundant_data()
    for dir_path in redundant_dirs:
        full_path = base_path / dir_path
        if move_to_archive(full_path, archive_path, "backup_data"):
            moved_dirs.append(str(full_path))
    
    print("\n3ï¸âƒ£ æ¸…ç†ç©ºè³‡æ–™å¤¾...")
    cleanup_empty_dirs(base_path)
    
    print("\n4ï¸âƒ£ å»ºç«‹æ¸…ç†æ‘˜è¦...")
    create_cleanup_summary(archive_path, moved_files, moved_dirs)
    
    return len(moved_files), len(moved_dirs)

def show_new_structure():
    """é¡¯ç¤ºæ•´ç†å¾Œçš„å°ˆæ¡ˆçµæ§‹"""
    print("\nğŸ“ æ•´ç†å¾Œçš„å°ˆæ¡ˆçµæ§‹:")
    print("=" * 50)
    
    structure = """
FinancialReports/
â”œâ”€â”€ ğŸ“„ financial_crawler.py        # ä¸»è¦çˆ¬èŸ²ç¨‹å¼
â”œâ”€â”€ ğŸ“„ test_crawler.py             # æ¸¬è©¦è…³æœ¬
â”œâ”€â”€ ğŸ“„ requirements.txt            # ä¾è³´å¥—ä»¶
â”œâ”€â”€ ğŸ“„ QUICK_START.md             # å¿«é€Ÿé–‹å§‹æŒ‡å—
â”œâ”€â”€ ğŸ“ config/                    # è¨­å®šæª”
â”œâ”€â”€ ğŸ“ data/                      # è³‡æ–™ç›®éŒ„
â”‚   â”œâ”€â”€ ğŸ“„ master_index.json      # ä¸»ç´¢å¼•æª”æ¡ˆ
â”‚   â”œâ”€â”€ ğŸ“ financial_reports/     # è²¡å ±æª”æ¡ˆ
â”‚   â””â”€â”€ ğŸ“ test_results/          # æ¸¬è©¦çµæœ
â”œâ”€â”€ ğŸ“ examples/                  # ç¯„ä¾‹æª”æ¡ˆ
â”‚   â”œâ”€â”€ ğŸ“„ single_query.json      # å–®ç­†æŸ¥è©¢ç¯„ä¾‹
â”‚   â”œâ”€â”€ ğŸ“„ batch_query.json       # æ‰¹æ¬¡æŸ¥è©¢ç¯„ä¾‹
â”‚   â””â”€â”€ ğŸ“„ demo_master_index.py   # ä¸»ç´¢å¼•ç¤ºç¯„
â”œâ”€â”€ ğŸ“ scripts/                   # å·¥å…·è…³æœ¬
â”‚   â”œâ”€â”€ ğŸ“„ rebuild_master_index.py # é‡å»ºä¸»ç´¢å¼•
â”‚   â”œâ”€â”€ ğŸ“ crawlers/              # çˆ¬èŸ²å·¥å…·
â”‚   â”œâ”€â”€ ğŸ“ tests/                 # æ¸¬è©¦å·¥å…·
â”‚   â”œâ”€â”€ ğŸ“ tools/                 # è¼”åŠ©å·¥å…·
â”‚   â””â”€â”€ ğŸ“ validation/            # é©—è­‰å·¥å…·
â”œâ”€â”€ ğŸ“ docs/                      # æ–‡æª”ç›®éŒ„
â”‚   â”œâ”€â”€ ğŸ“ guides/                # ä½¿ç”¨æŒ‡å—
â”‚   â””â”€â”€ ğŸ“ reports/               # æ¸¬è©¦å ±å‘Š
â”œâ”€â”€ ğŸ“ output/                    # è¼¸å‡ºç›®éŒ„
â””â”€â”€ ğŸ“ archive/                   # å­˜æª”ç›®éŒ„ (æ–°å¢)
    â”œâ”€â”€ ğŸ“ old_docs/              # èˆŠæ–‡æª”
    â”œâ”€â”€ ğŸ“ old_reports/           # èˆŠå ±å‘Š
    â”œâ”€â”€ ğŸ“ duplicate_files/       # é‡è¤‡æª”æ¡ˆ
    â””â”€â”€ ğŸ“ backup_data/           # å‚™ä»½è³‡æ–™
"""
    
    print(structure)

def main():
    """ä¸»ç¨‹å¼"""
    print("ğŸ§¹ å°ˆæ¡ˆè³‡æ–™å¤¾æ•´ç†å·¥å…·")
    print("=" * 50)
    print("æ­¤å·¥å…·å°‡:")
    print("â€¢ ç§»é™¤é‡è¤‡çš„æ–‡æª”æª”æ¡ˆ")
    print("â€¢ æ•´ç†å†—é¤˜çš„è³‡æ–™ç›®éŒ„") 
    print("â€¢ å»ºç«‹çµ±ä¸€çš„å­˜æª”è³‡æ–™å¤¾")
    print("â€¢ æ¸…ç†ç©ºè³‡æ–™å¤¾")
    print("â€¢ å„ªåŒ–å°ˆæ¡ˆçµæ§‹")
    print("=" * 50)
    
    # ç¢ºèªåŸ·è¡Œ
    response = input("ğŸ¤” ç¢ºå®šè¦åŸ·è¡Œæ•´ç†å—ï¼Ÿ(y/N): ").strip().lower()
    if response != 'y':
        print("âŒ å–æ¶ˆæ•´ç†")
        return
    
    print("\nğŸš€ é–‹å§‹æ•´ç†...")
    
    try:
        moved_files, moved_dirs = reorganize_project()
        
        print(f"\nâœ… æ•´ç†å®Œæˆ!")
        print(f"   ğŸ“„ ç§»å‹•æª”æ¡ˆ: {moved_files} å€‹")
        print(f"   ğŸ“ ç§»å‹•ç›®éŒ„: {moved_dirs} å€‹")
        print(f"   ğŸ—‚ï¸ å­˜æª”ä½ç½®: archive/")
        
        show_new_structure()
        
        print("\nğŸ¯ å»ºè­°å¾ŒçºŒå‹•ä½œ:")
        print("1. æª¢æŸ¥ archive/ è³‡æ–™å¤¾ç¢ºèªç§»å‹•çš„æª”æ¡ˆ")
        print("2. æ¸¬è©¦ä¸»è¦åŠŸèƒ½: python financial_crawler.py --stats")
        print("3. åŸ·è¡Œå®Œæ•´æ¸¬è©¦: python test_crawler.py")
        print("4. å¦‚ç¢ºèªç„¡å•é¡Œï¼Œå¯åˆªé™¤ archive/ è³‡æ–™å¤¾")
        
    except Exception as e:
        print(f"âŒ æ•´ç†éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
        return 1
    
    return 0

if __name__ == '__main__':
    import sys
    sys.exit(main())
